# MLOPS-Vechile-Insuracnce-pipeline


## üöÄ Overview
This project is an end-to-end MLOps pipeline that streamlines the process of building, deploying, and maintaining machine learning models efficiently. The project integrates data ingestion, validation, transformation, model training, evaluation, and deployment with cloud services like AWS and MongoDB. The goal is to impress recruiters and showcase expertise in MLOps principles, best practices, and cutting-edge tools.

## üìå Key Features
- **Automated Project Setup**: Generate a structured project template effortlessly.
- **Environment Management**: Virtual environment setup and dependency management.
- **MongoDB Integration**: Data storage and retrieval from MongoDB Atlas.
- **Logging & Exception Handling**: Robust logging and error tracking.
- **Data Ingestion & Transformation**: Seamless data fetching, validation, and transformation.
- **Model Training & Evaluation**: Advanced model training and performance tracking.
- **AWS Cloud Deployment**: Model storage and deployment with S3, EC2, and ECR.
- **CI/CD Pipeline**: Automated build, test, and deployment workflows with GitHub Actions.

---

## üõ† Tech Stack
- **Programming Language**: Python 3.12
- **Frameworks & Libraries**: Pandas, NumPy, Scikit-learn, TensorFlow/PyTorch
- **Database**: MongoDB Atlas
- **Cloud Services**: AWS S3, EC2, ECR, IAM
- **Containerization & Orchestration**: Docker
- **CI/CD**: GitHub Actions
- **Logging & Monitoring**: Python Logging Module

---

## üìÇ Project Structure
```
mlops_project/
‚îÇ‚îÄ‚îÄ src/                       # Source Code
‚îÇ   ‚îú‚îÄ‚îÄ components/            # Core Modules (Data Ingestion, Model Training, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ configuration/          # Configuration files for DB & Cloud
‚îÇ   ‚îú‚îÄ‚îÄ entity/                 # Entities and Data Classes
‚îÇ   ‚îú‚îÄ‚îÄ utils/                  # Helper Functions
‚îÇ   ‚îú‚îÄ‚îÄ aws_storage/            # AWS S3 Integration
‚îÇ‚îÄ‚îÄ notebook/                   # Jupyter Notebooks for EDA & Experimentation
‚îÇ‚îÄ‚îÄ artifacts/                   # Model Artifacts & Logs
‚îÇ‚îÄ‚îÄ .github/workflows/           # CI/CD Workflows
‚îÇ‚îÄ‚îÄ Dockerfile                   # Containerization
‚îÇ‚îÄ‚îÄ pyproject.toml               # Package Configuration
‚îÇ‚îÄ‚îÄ setup.py                     # Package Setup
‚îÇ‚îÄ‚îÄ requirements.txt             # Dependencies
‚îÇ‚îÄ‚îÄ README.md                    # Project Documentation
```

---

## üìå Installation & Setup

### 1Ô∏è‚É£ Create & Activate Virtual Environment
```sh
conda create -n envmlop python=3.12 -y
conda activate envmlop
```

### 2Ô∏è‚É£ Install Dependencies
```sh
pip install -r requirements.txt
```

### 3Ô∏è‚É£ Verify Package Installation
```sh
pip list
```

---

## üóÑÔ∏è MongoDB Setup
### 1Ô∏è‚É£ Sign Up & Create Cluster
- Sign up at [MongoDB Atlas](https://www.mongodb.com/atlas)
- Create a new project and cluster (M0 tier)

### 2Ô∏è‚É£ Configure Database User
- Create a new database user with access credentials.
- Set Network Access to **0.0.0.0/0** to allow connections from any IP.

### 3Ô∏è‚É£ Obtain Connection String
- Navigate to *Database > Get Connection String*.
- Select **Python Driver (3.6 or later)** and copy the connection URL.

### 4Ô∏è‚É£ Load Data into MongoDB
```python
from pymongo import MongoClient
client = MongoClient("your_mongo_connection_string")
db = client["your_database"]
collection = db["your_collection"]
# Insert your data here
```

---

## ‚öôÔ∏è Logging & Exception Handling
- Implemented **logging** for better debugging.
- Custom **exception handling** framework.

---

## üìä Data Pipeline Implementation

### üîπ Data Ingestion
- Fetch raw data from MongoDB.
- Convert into structured **Pandas DataFrame**.
- Store processed data in artifacts directory.

### üîπ Data Validation
- Define schema in `config.schema.yaml`.
- Validate data against schema constraints.

### üîπ Data Transformation
- Feature Engineering & Scaling.
- Handle missing values & outliers.

### üîπ Model Training
- Train models using **Scikit-learn, TensorFlow, or PyTorch**.
- Save trained models to **artifacts directory**.

### üîπ Model Evaluation
- Compare model performance.
- Implement **threshold-based validation** before deployment.

### üîπ Model Deployment
- Upload trained models to **AWS S3**.
- Deploy model on **EC2 instance**.

---

## ‚òÅÔ∏è AWS Integration
### 1Ô∏è‚É£ Configure AWS Credentials
```sh
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
```

### 2Ô∏è‚É£ Create & Configure S3 Bucket
```sh
aws s3 mb s3://my-model-mlopsproj
```

### 3Ô∏è‚É£ Push Model to S3
```sh
aws s3 cp model.pkl s3://my-model-mlopsproj/model-registry/
```

---

## üõ†Ô∏è CI/CD Pipeline
### 1Ô∏è‚É£ Setup GitHub Secrets
Navigate to *GitHub Project > Settings > Secrets and Variables > Actions* and add:
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`
- `AWS_DEFAULT_REGION`
- `ECR_REPO`

### 2Ô∏è‚É£ Configure Self-Hosted Runner on EC2
```sh
./run.sh
```

### 3Ô∏è‚É£ Enable CI/CD Workflow
- Push code to GitHub repository.
- GitHub Actions triggers CI/CD pipeline.

---

## üö¢ Docker & EC2 Deployment
### 1Ô∏è‚É£ Build & Push Docker Image
```sh
docker build -t mlops-app .
docker tag mlops-app:latest <AWS_ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/vehicleproj:latest
docker push <AWS_ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/vehicleproj:latest
```

### 2Ô∏è‚É£ Deploy on EC2 & Expose API
```sh
docker run -p 5080:5000 mlops-app
```

### 3Ô∏è‚É£ Access Deployed Application
Open a browser and visit:
```
http://<EC2_PUBLIC_IP>:5080
```

---

## üìà Model Training & Prediction
### Train Model
```sh
curl -X POST http://<EC2_PUBLIC_IP>:5080/training
```

### Predict
```sh
curl -X POST http://<EC2_PUBLIC_IP>:5080/predict -H "Content-Type: application/json" -d '{ "input_data": [...] }'
```

---

## üéØ Conclusion
This MLOps project demonstrates a complete pipeline from **data ingestion to model deployment** in a production-ready environment. By leveraging **MongoDB, AWS, Docker, and CI/CD**, this project ensures **scalability, reproducibility, and automation**.

---

